{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tesseract on Patches on a Single Image\n",
    "\n",
    "### Median Blur and Kernel Filter on every patch of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "img = cv2.imread('/mnt/c/Users/parth/Desktop/CODING/AmazonML/archive/student_resource 3/11lshEUmCrL.jpg')\n",
    "\n",
    "# Parameters\n",
    "patch_size = (50, 50)  # Define the size of each patch (smaller size)\n",
    "step_size = 10       # Define the step size to create overlapping patches\n",
    "resize_to = (250, 250)   # Size to resize each patch\n",
    "\n",
    "# Calculate number of patches\n",
    "img_height, img_width, _ = img.shape\n",
    "patch_coordinates = [(x, y) for y in range(0, img_height - patch_size[0] + 1, step_size) \n",
    "                     for x in range(0, img_width - patch_size[1] + 1, step_size)]\n",
    "\n",
    "# Function to process each patch\n",
    "def process_patch(x, y):\n",
    "    # Extract the patch\n",
    "    patch = img[y:y + patch_size[0], x:x + patch_size[1]]\n",
    "\n",
    "    # Resize the patch\n",
    "    patch = cv2.resize(patch, resize_to)\n",
    "\n",
    "    # Apply median blur to the patch for denoising\n",
    "    patch = cv2.medianBlur(patch, 5)\n",
    "\n",
    "    # Apply filter for sharpening using kernel\n",
    "    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
    "    patch = cv2.filter2D(patch, -1, kernel)\n",
    "\n",
    "    # Use Tesseract to detect text in the patch\n",
    "    d = pytesseract.image_to_data(patch, output_type=Output.DICT)\n",
    "\n",
    "    # Delete empty strings from detected text\n",
    "    d['text'] = [text for text in d['text'] if text]\n",
    "    \n",
    "    # Skip this patch if no text is detected or only empty text is found\n",
    "    if len(d['text']) == 0 or (len(d['text']) == 1 and d['text'][0] == ''):\n",
    "        return None, None\n",
    "\n",
    "    # Draw rectangles around detected text in the patch\n",
    "    n_boxes = len(d['level'])\n",
    "    for i in range(n_boxes):\n",
    "        (x_patch, y_patch, w, h) = (d['left'][i], d['top'][i], d['width'][i], d['height'][i])\n",
    "        cv2.rectangle(patch, (x_patch, y_patch), (x_patch + w, y_patch + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Convert BGR patch to RGB for displaying\n",
    "    patch_rgb = cv2.cvtColor(patch, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    \n",
    "    return patch_rgb, f\"Patch at ({x}, {y}) : {d['text']}\"\n",
    "\n",
    "# Using ThreadPoolExecutor for multithreading\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    # Submit each patch processing task to the thread pool\n",
    "    futures = [executor.submit(process_patch, x, y) for (x, y) in patch_coordinates]\n",
    "\n",
    "    # Use tqdm to track progress\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing patches\"):\n",
    "        patch_rgb, title= future.result()\n",
    "\n",
    "        if patch_rgb is not None:\n",
    "            # Show the patch with detected text\n",
    "            # Print the detected text\n",
    "            \n",
    "            plt.figure(figsize=(4, 4))\n",
    "            plt.imshow(patch_rgb)\n",
    "            plt.title(title)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tesseract on Whole Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('/mnt/c/Users/parth/Desktop/CODING/AmazonML/archive/student_resource 3/11lshEUmCrL.jpg')\n",
    "\n",
    "# Show the img\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(img)\n",
    "plt.title(\"title\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a result file from the train.csv file to add the results of the Tesseract on the whole images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Premature end of JPEG file\n",
      "Premature end of JPEG file\n",
      "Premature end of JPEG file\n",
      "Premature end of JPEG file\n",
      "Premature end of JPEG file\n",
      "Premature end of JPEG file\n",
      "Premature end of JPEG file\n",
      "Premature end of JPEG file\n",
      "Premature end of JPEG file\n",
      "Premature end of JPEG file\n",
      "Premature end of JPEG file\n",
      "Premature end of JPEG file\n",
      "Premature end of JPEG file\n",
      "Premature end of JPEG file\n",
      "Premature end of JPEG file\n",
      "Premature end of JPEG file\n",
      "Premature end of JPEG file\n",
      "Premature end of JPEG file\n",
      "Premature end of JPEG file\n",
      "Premature end of JPEG file\n",
      "Premature end of JPEG file\n",
      "Premature end of JPEG file\n",
      "Premature end of JPEG file\n",
      "Premature end of JPEG file\n",
      "Premature end of JPEG file\n",
      "Premature end of JPEG file\n",
      "Premature end of JPEG file\n",
      "Premature end of JPEG file\n",
      "Premature end of JPEG file\n",
      "Premature end of JPEG file\n",
      "Premature end of JPEG file\n",
      "Premature end of JPEG file\n",
      "Premature end of JPEG file\n",
      "Premature end of JPEG file\n",
      "Premature end of JPEG file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final CSV created at: /mnt/c/Users/parth/Desktop/CODING/AmazonML/archive/student_resource 3/final_output.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Folder containing images\n",
    "image_folder = '/mnt/c/Users/parth/Desktop/CODING/AmazonML/archive/student_resource 3/train_images'  # Change this to your image folder path\n",
    "output_folder = '/mnt/c/Users/parth/Desktop/CODING/AmazonML/archive/student_resource 3/'  # Path to save thread-wise CSV files\n",
    "\n",
    "# Function to process an image and extract text\n",
    "def process_image(image_path):\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    # Apply median blur to the image for denoising\n",
    "    img = cv2.medianBlur(img, 5)\n",
    "\n",
    "    # Apply filter for sharpening using kernel\n",
    "    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
    "    img = cv2.filter2D(img, -1, kernel)\n",
    "\n",
    "    # Use Tesseract to detect text in the whole image\n",
    "    d = pytesseract.image_to_data(img, output_type=Output.DICT)\n",
    "\n",
    "    # Prepare the list of tuples with text and coordinates\n",
    "    extracted_data = []\n",
    "    for i, text in enumerate(d['text']):\n",
    "        if text.strip():  # Skip empty text\n",
    "            coordinates = (d['left'][i], d['top'][i], d['width'][i], d['height'][i])\n",
    "            extracted_data.append((text, coordinates))\n",
    "\n",
    "    # Get the image name from the path\n",
    "    image_name = os.path.basename(image_path)\n",
    "\n",
    "    return image_name, extracted_data\n",
    "\n",
    "# Append to thread-specific CSV file\n",
    "def append_to_csv(thread_id, image_name, extracted_data):\n",
    "    # Fix empty and non-empty lists to be stored consistently as strings\n",
    "    extracted_data_str = str(extracted_data)\n",
    "    \n",
    "    # Create a new row as a DataFrame\n",
    "    new_row = pd.DataFrame({'image_name': [image_name], 'extracted_data': [extracted_data_str]})\n",
    "    \n",
    "    # Output file for the thread\n",
    "    csv_file_path = os.path.join(output_folder, f'output{thread_id}.csv')\n",
    "\n",
    "    # Check if CSV exists, if not create a new one with headers\n",
    "    if not os.path.exists(csv_file_path):\n",
    "        new_row.to_csv(csv_file_path, index=False)\n",
    "    else:\n",
    "        # Append to the existing CSV\n",
    "        new_row.to_csv(csv_file_path, mode='a', header=False, index=False)\n",
    "\n",
    "# Function to process images in a specific chunk\n",
    "def process_chunk(thread_id, image_paths_chunk):\n",
    "    for image_path in image_paths_chunk:\n",
    "        image_name, extracted_data = process_image(image_path)\n",
    "        append_to_csv(thread_id, image_name, extracted_data)\n",
    "\n",
    "# Function to divide image paths into chunks\n",
    "def divide_chunks(lst, n):\n",
    "    # Yield n parts of the list\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "# Process all images in the folder\n",
    "image_paths = [os.path.join(image_folder, img) for img in os.listdir(image_folder) if img.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "\n",
    "# Divide image paths into 16 chunks (one per thread)\n",
    "num_threads = 16\n",
    "chunks = list(divide_chunks(image_paths, len(image_paths) // num_threads))\n",
    "\n",
    "# Process chunks in parallel using ThreadPoolExecutor\n",
    "with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "    for thread_id, chunk in enumerate(chunks):\n",
    "        executor.submit(process_chunk, thread_id, chunk)\n",
    "\n",
    "# Combine all thread-specific CSV files into one final CSV\n",
    "final_csv_path = os.path.join(output_folder, 'final_output.csv')\n",
    "\n",
    "# Create the final CSV by combining all thread CSVs\n",
    "combined_df = pd.concat([pd.read_csv(os.path.join(output_folder, f'output{thread_id}.csv')) for thread_id in range(num_threads)])\n",
    "\n",
    "# Save the combined data to the final CSV\n",
    "combined_df.to_csv(final_csv_path, index=False)\n",
    "\n",
    "print(f\"Final CSV created at: {final_csv_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
