{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tesseract on Patches on a Single Image\n",
    "\n",
    "### Median Blur and Kernel Filter on every patch of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "img = cv2.imread('/mnt/c/Users/parth/Desktop/CODING/AmazonML/archive/student_resource 3/11lshEUmCrL.jpg')\n",
    "\n",
    "# Parameters\n",
    "patch_size = (50, 50)  # Define the size of each patch (smaller size)\n",
    "step_size = 10       # Define the step size to create overlapping patches\n",
    "resize_to = (250, 250)   # Size to resize each patch\n",
    "\n",
    "# Calculate number of patches\n",
    "img_height, img_width, _ = img.shape\n",
    "patch_coordinates = [(x, y) for y in range(0, img_height - patch_size[0] + 1, step_size) \n",
    "                     for x in range(0, img_width - patch_size[1] + 1, step_size)]\n",
    "\n",
    "# Function to process each patch\n",
    "def process_patch(x, y):\n",
    "    # Extract the patch\n",
    "    patch = img[y:y + patch_size[0], x:x + patch_size[1]]\n",
    "\n",
    "    # Resize the patch\n",
    "    patch = cv2.resize(patch, resize_to)\n",
    "\n",
    "    # Apply median blur to the patch for denoising\n",
    "    patch = cv2.medianBlur(patch, 5)\n",
    "\n",
    "    # Apply filter for sharpening using kernel\n",
    "    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
    "    patch = cv2.filter2D(patch, -1, kernel)\n",
    "\n",
    "    # Use Tesseract to detect text in the patch\n",
    "    d = pytesseract.image_to_data(patch, output_type=Output.DICT)\n",
    "\n",
    "    # Delete empty strings from detected text\n",
    "    d['text'] = [text for text in d['text'] if text]\n",
    "    \n",
    "    # Skip this patch if no text is detected or only empty text is found\n",
    "    if len(d['text']) == 0 or (len(d['text']) == 1 and d['text'][0] == ''):\n",
    "        return None, None\n",
    "\n",
    "    # Draw rectangles around detected text in the patch\n",
    "    n_boxes = len(d['level'])\n",
    "    for i in range(n_boxes):\n",
    "        (x_patch, y_patch, w, h) = (d['left'][i], d['top'][i], d['width'][i], d['height'][i])\n",
    "        cv2.rectangle(patch, (x_patch, y_patch), (x_patch + w, y_patch + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Convert BGR patch to RGB for displaying\n",
    "    patch_rgb = cv2.cvtColor(patch, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    \n",
    "    return patch_rgb, f\"Patch at ({x}, {y}) : {d['text']}\"\n",
    "\n",
    "# Using ThreadPoolExecutor for multithreading\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    # Submit each patch processing task to the thread pool\n",
    "    futures = [executor.submit(process_patch, x, y) for (x, y) in patch_coordinates]\n",
    "\n",
    "    # Use tqdm to track progress\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing patches\"):\n",
    "        patch_rgb, title= future.result()\n",
    "\n",
    "        if patch_rgb is not None:\n",
    "            # Show the patch with detected text\n",
    "            # Print the detected text\n",
    "            \n",
    "            plt.figure(figsize=(4, 4))\n",
    "            plt.imshow(patch_rgb)\n",
    "            plt.title(title)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tesseract on Whole Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('/mnt/c/Users/parth/Desktop/CODING/AmazonML/archive/student_resource 3/11lshEUmCrL.jpg')\n",
    "\n",
    "# Show the img\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(img)\n",
    "plt.title(\"title\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a result file from the train.csv file to add the results of the Tesseract on the whole images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Folder containing images\n",
    "image_folder = '/mnt/c/Users/parth/Desktop/CODING/AmazonML/archive/student_resource 3/train_images'  # Change this to your image folder path\n",
    "output_folder = '/mnt/c/Users/parth/Desktop/CODING/AmazonML/archive/student_resource 3/'  # Path to save thread-wise CSV files\n",
    "\n",
    "# Function to process an image and extract text\n",
    "def process_image(image_path):\n",
    "    try:\n",
    "        # Load the image\n",
    "        img = cv2.imread(image_path)\n",
    "\n",
    "        # Check if the image was loaded successfully\n",
    "        if img is None:\n",
    "            raise ValueError(f\"Image {image_path} could not be read (possibly corrupted).\")\n",
    "\n",
    "        # Apply median blur to the image for denoising\n",
    "        img = cv2.medianBlur(img, 5)\n",
    "\n",
    "        # Apply filter for sharpening using kernel\n",
    "        kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
    "        img = cv2.filter2D(img, -1, kernel)\n",
    "\n",
    "        # Use Tesseract to detect text in the whole image\n",
    "        d = pytesseract.image_to_data(img, output_type=Output.DICT)\n",
    "\n",
    "        # Prepare the list of tuples with text and coordinates\n",
    "        extracted_data = []\n",
    "        for i, text in enumerate(d['text']):\n",
    "            if text.strip():  # Skip empty text\n",
    "                coordinates = (d['left'][i], d['top'][i], d['width'][i], d['height'][i])\n",
    "                extracted_data.append((text, coordinates))\n",
    "\n",
    "        # Get the image name from the path\n",
    "        image_name = os.path.basename(image_path)\n",
    "\n",
    "        return image_name, extracted_data, False  # False indicates no error\n",
    "\n",
    "    except Exception as e:\n",
    "        # Log the exception with the image name\n",
    "        print(f\"Error processing image {image_path}: {str(e)}\")\n",
    "        return None, None, True  # True indicates an error (skipped image)\n",
    "\n",
    "# Append to thread-specific CSV file\n",
    "def append_to_csv(thread_id, image_name, extracted_data):\n",
    "    if image_name is not None and extracted_data is not None:\n",
    "        # Fix empty and non-empty lists to be stored consistently as strings\n",
    "        extracted_data_str = str(extracted_data)\n",
    "        \n",
    "        # Create a new row as a DataFrame\n",
    "        new_row = pd.DataFrame({'image_name': [image_name], 'extracted_data': [extracted_data_str]})\n",
    "        \n",
    "        # Output file for the thread\n",
    "        csv_file_path = os.path.join(output_folder, f'output{thread_id}.csv')\n",
    "\n",
    "        # Check if CSV exists, if not create a new one with headers\n",
    "        if not os.path.exists(csv_file_path):\n",
    "            new_row.to_csv(csv_file_path, index=False)\n",
    "        else:\n",
    "            # Append to the existing CSV\n",
    "            new_row.to_csv(csv_file_path, mode='a', header=False, index=False)\n",
    "\n",
    "# Function to process images in a specific chunk and count skipped images\n",
    "def process_chunk(thread_id, image_paths_chunk):\n",
    "    skipped_count = 0\n",
    "    for image_path in image_paths_chunk:\n",
    "        image_name, extracted_data, is_skipped = process_image(image_path)\n",
    "        if is_skipped:\n",
    "            skipped_count += 1\n",
    "        else:\n",
    "            append_to_csv(thread_id, image_name, extracted_data)\n",
    "    print(f\"Thread {thread_id} finished with {skipped_count} skipped images.\")\n",
    "\n",
    "# Function to check if all chunks are roughly equal in size\n",
    "def check_chunk_sizes(chunks, total_images, num_threads):\n",
    "    chunk_sizes = [len(chunk) for chunk in chunks]\n",
    "    expected_size = total_images // num_threads\n",
    "    for i, size in enumerate(chunk_sizes):\n",
    "        print(f\"Chunk {i} size: {size} (Expected: ~{expected_size})\")\n",
    "\n",
    "# Process all images in the folder\n",
    "image_paths = [os.path.join(image_folder, img) for img in os.listdir(image_folder) if img.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "\n",
    "\n",
    "# # Checking if the code works so currently only taking first 100 images from the folder\n",
    "# image_paths = image_paths[:1000]\n",
    "\n",
    "total_images = len(image_paths)\n",
    "\n",
    "# Divide image paths into 16 roughly equal parts\n",
    "num_threads = 20\n",
    "chunks = np.array_split(image_paths, num_threads)  # Use numpy to split into roughly equal parts\n",
    "\n",
    "# Check chunk sizes to verify even distribution\n",
    "check_chunk_sizes(chunks, total_images, num_threads)\n",
    "\n",
    "# Process chunks in parallel using ThreadPoolExecutor\n",
    "with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "    for thread_id, chunk in enumerate(chunks):\n",
    "        executor.submit(process_chunk, thread_id, chunk)\n",
    "\n",
    "# Combine all thread-specific CSV files into one final CSV\n",
    "final_csv_path = os.path.join(output_folder, 'final_output.csv')\n",
    "\n",
    "# Create the final CSV by combining all thread CSVs\n",
    "combined_df = pd.concat([pd.read_csv(os.path.join(output_folder, f'output{thread_id}.csv')) for thread_id in range(num_threads)], ignore_index=True)\n",
    "\n",
    "# Save the combined data to the final CSV\n",
    "combined_df.to_csv(final_csv_path, index=False)\n",
    "\n",
    "print(f\"Final CSV created at: {final_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final CSV created at: /mnt/c/Users/parth/Desktop/CODING/AmazonML/archive/student_resource 3/final_output.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "# Folder containing images\n",
    "image_folder = '/mnt/c/Users/parth/Desktop/CODING/AmazonML/archive/student_resource 3/train_images'  # Change this to your image folder path\n",
    "output_folder = '/mnt/c/Users/parth/Desktop/CODING/AmazonML/archive/student_resource 3/'  # Path to save thread-wise CSV files\n",
    "# Combine all thread-specific CSV files into one final CSV\n",
    "final_csv_path = os.path.join(output_folder, 'final_output.csv')\n",
    "# Create the final CSV by combining all thread CSVs\n",
    "combined_df = pd.concat([pd.read_csv(os.path.join(output_folder, f'output{thread_id}.csv')) for thread_id in range(20)], ignore_index=True)\n",
    "\n",
    "# Save the combined data to the final CSV\n",
    "combined_df.to_csv(final_csv_path, index=False)\n",
    "\n",
    "print(f\"Final CSV created at: {final_csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying PaddleOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import os\n",
    "# from concurrent.futures import ThreadPoolExecutor\n",
    "# from paddleocr import PaddleOCR, draw_ocr\n",
    "# from PIL import Image\n",
    "# import gc\n",
    "\n",
    "\n",
    "# os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "\n",
    "# # Initialize PaddleOCR with a specific language model (switch the language as needed)\n",
    "# # Enable angle classifier for detecting and correcting text rotation\n",
    "# ocr = PaddleOCR(use_angle_cls=True, use_gpu=True, lang='en',rec_batch_num=1)  # lang='korean', 'ch', etc., depending on the language you're using\n",
    "\n",
    "# # Folder containing images\n",
    "# image_folder = '/mnt/c/Users/parth/Desktop/CODING/AmazonML/archive/student_resource 3/train_images'\n",
    "# output_folder = '/mnt/c/Users/parth/Desktop/CODING/AmazonML/archive/student_resource 3/'\n",
    "\n",
    "# # Function to process an image and extract text using PaddleOCR\n",
    "# def process_image(image_path):\n",
    "#     try:\n",
    "#         # Load the image\n",
    "#         img = cv2.imread(image_path)\n",
    "\n",
    "#         # Check if the image was loaded successfully\n",
    "#         if img is None:\n",
    "#             raise ValueError(f\"Image {image_path} could not be read (possibly corrupted).\")\n",
    "\n",
    "#         # Perform OCR using PaddleOCR\n",
    "#         result = ocr.ocr(image_path)  # You can specify det=False or rec=False as needed\n",
    "\n",
    "#         # Prepare the list of tuples with text and coordinates\n",
    "#         extracted_data = []\n",
    "#         for line in result:\n",
    "#             text = line[1][0]  # Extract recognized text\n",
    "#             coordinates = line[0]  # Extract the bounding box coordinates\n",
    "#             extracted_data.append((text, coordinates))\n",
    "\n",
    "#         # Visualize and save the OCR results\n",
    "#         image = Image.open(image_path).convert('RGB')\n",
    "#         boxes = [line[0] for line in result]\n",
    "#         txts = [line[1][0] for line in result]\n",
    "#         scores = [line[1][1] for line in result]\n",
    "\n",
    "#         # You may need to provide the path to a font file for the language\n",
    "#         font_path = 'doc/fonts/korean.ttf'  # Replace this with the correct path for your language\n",
    "#         im_show = draw_ocr(image, boxes, txts, scores, font_path=font_path)\n",
    "#         im_show = Image.fromarray(im_show)\n",
    "#         output_img_path = os.path.join(output_folder, f\"ocr_result_{os.path.basename(image_path)}\")\n",
    "#         im_show.save(output_img_path)\n",
    "\n",
    "#         # Get the image name from the path\n",
    "#         image_name = os.path.basename(image_path)\n",
    "\n",
    "#         return image_name, extracted_data, False  # False indicates no error\n",
    "\n",
    "#     except Exception as e:\n",
    "#         # Log the exception with the image name\n",
    "#         print(f\"Error processing image {image_path}: {str(e)}\")\n",
    "#         return None, None, True  # True indicates an error (skipped image)\n",
    "\n",
    "#     finally:\n",
    "#         del img\n",
    "#         gc.collect()\n",
    "\n",
    "# # Append to thread-specific CSV file\n",
    "# def append_to_csv(thread_id, image_name, extracted_data):\n",
    "#     if image_name is not None and extracted_data is not None:\n",
    "#         # Fix empty and non-empty lists to be stored consistently as strings\n",
    "#         extracted_data_str = str(extracted_data)\n",
    "        \n",
    "#         # Create a new row as a DataFrame\n",
    "#         new_row = pd.DataFrame({'image_name': [image_name], 'extracted_data': [extracted_data_str]})\n",
    "        \n",
    "#         # Output file for the thread\n",
    "#         csv_file_path = os.path.join(output_folder, f'output{thread_id}.csv')\n",
    "\n",
    "#         # Check if CSV exists, if not create a new one with headers\n",
    "#         if not os.path.exists(csv_file_path):\n",
    "#             new_row.to_csv(csv_file_path, index=False)\n",
    "#         else:\n",
    "#             # Append to the existing CSV\n",
    "#             new_row.to_csv(csv_file_path, mode='a', header=False, index=False)\n",
    "\n",
    "# # Function to process images in a specific chunk and count skipped images\n",
    "# def process_chunk(thread_id, image_paths_chunk):\n",
    "#     skipped_count = 0\n",
    "#     for image_path in image_paths_chunk:\n",
    "#         image_name, extracted_data, is_skipped = process_image(image_path)\n",
    "#         if is_skipped:\n",
    "#             skipped_count += 1\n",
    "#         else:\n",
    "#             append_to_csv(thread_id, image_name, extracted_data)\n",
    "#     print(f\"Thread {thread_id} finished with {skipped_count} skipped images.\")\n",
    "\n",
    "# # Process all images in the folder\n",
    "# image_paths = [os.path.join(image_folder, img) for img in os.listdir(image_folder) if img.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "\n",
    "# # Use a smaller batch for testing, for example, the first 100 images\n",
    "# image_paths = image_paths[:100]  # You can adjust this as needed for testing\n",
    "\n",
    "# total_images = len(image_paths)\n",
    "# num_threads = 10\n",
    "# chunks = np.array_split(image_paths, num_threads)\n",
    "\n",
    "# # Process images using ThreadPoolExecutor\n",
    "# with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "#     for thread_id, chunk in enumerate(chunks):\n",
    "#         executor.submit(process_chunk, thread_id, chunk)\n",
    "\n",
    "# # Combine all CSV files into one final CSV\n",
    "# final_csv_path = os.path.join(output_folder, 'final_output.csv')\n",
    "# combined_df = pd.concat([pd.read_csv(os.path.join(output_folder, f'output{thread_id}.csv')) for thread_id in range(num_threads)], ignore_index=True)\n",
    "# combined_df.to_csv(final_csv_path, index=False)\n",
    "\n",
    "# print(f\"Final CSV created at: {final_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "import GPUtil\n",
    "\n",
    "# Function to check RAM usage\n",
    "def check_ram():\n",
    "    memory = psutil.virtual_memory()\n",
    "    total_memory = memory.total / (1024 ** 3)  # Convert bytes to GB\n",
    "    available_memory = memory.available / (1024 ** 3)\n",
    "    used_memory = memory.used / (1024 ** 3)\n",
    "\n",
    "    print(f\"Total Memory: {total_memory:.2f} GB\")\n",
    "    print(f\"Available Memory: {available_memory:.2f} GB\")\n",
    "    print(f\"Used Memory: {used_memory:.2f} GB\")\n",
    "\n",
    "# Function to check GPU usage\n",
    "def check_gpu():\n",
    "    gpus = GPUtil.getGPUs()\n",
    "    if gpus:\n",
    "        for gpu in gpus:\n",
    "            print(f\"GPU: {gpu.name}\")\n",
    "            print(f\"Total Memory: {gpu.memoryTotal} MB\")\n",
    "            print(f\"Used Memory: {gpu.memoryUsed} MB\")\n",
    "            print(f\"Free Memory: {gpu.memoryFree} MB\")\n",
    "            print(f\"GPU Load: {gpu.load * 100}%\")\n",
    "    else:\n",
    "        print(\"No GPU detected.\")\n",
    "\n",
    "# Run both checks\n",
    "check_ram()\n",
    "check_gpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
